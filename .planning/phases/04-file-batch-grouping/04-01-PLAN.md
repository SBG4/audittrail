---
phase: 04-file-batch-grouping
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - server/src/models/file_batch.py
  - server/src/models/__init__.py
  - server/src/schemas/file_batch.py
  - server/src/routers/file_batches.py
  - server/src/main.py
  - server/alembic/versions/005_create_file_batches_table.py
autonomous: true

must_haves:
  truths:
    - "File batch CRUD endpoints accept and return correct data"
    - "Batches are scoped to events which are scoped to cases"
    - "Deleting an event cascades to delete its batches"
  artifacts:
    - path: "server/src/models/file_batch.py"
      provides: "FileBatch SQLAlchemy model"
      contains: "class FileBatch"
    - path: "server/src/schemas/file_batch.py"
      provides: "Pydantic schemas for batch CRUD"
      exports: ["FileBatchCreate", "FileBatchUpdate", "FileBatchRead"]
    - path: "server/src/routers/file_batches.py"
      provides: "Nested CRUD router for file batches"
      contains: "router = APIRouter"
    - path: "server/alembic/versions/005_create_file_batches_table.py"
      provides: "Migration creating file_batches table"
      contains: "create_table"
  key_links:
    - from: "server/src/routers/file_batches.py"
      to: "server/src/models/file_batch.py"
      via: "SQLAlchemy queries"
      pattern: "FileBatch\\("
    - from: "server/src/main.py"
      to: "server/src/routers/file_batches.py"
      via: "app.include_router"
      pattern: "include_router.*file_batch"
    - from: "server/src/models/file_batch.py"
      to: "Event model (from Phase 3)"
      via: "ForeignKey events.id"
      pattern: "ForeignKey.*events\\.id"
---

<objective>
File batch API with full CRUD operations, event association, and batch metadata.

Purpose: Provides the backend data layer for organizing file evidence into labeled batch groups attached to timeline events. Enables auditors to create, read, update, and delete file batch metadata (label, count, description, file types) scoped to specific events.

Output: FileBatch model, Pydantic schemas, CRUD router, and Alembic migration.
</objective>

<execution_context>
@/Users/shiro/.claude/get-shit-done/workflows/execute-plan.md
@/Users/shiro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-file-batch-grouping/04-RESEARCH.md
@server/src/models/case.py
@server/src/schemas/case.py
@server/src/routers/cases.py
@server/src/models/__init__.py
@server/src/main.py
@server/src/database.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: FileBatch model, schemas, and migration</name>
  <files>
    server/src/models/file_batch.py
    server/src/models/__init__.py
    server/src/schemas/file_batch.py
    server/alembic/versions/005_create_file_batches_table.py
  </files>
  <action>
    Create FileBatch SQLAlchemy model in `server/src/models/file_batch.py`:
    - UUID primary key (default=uuid.uuid4)
    - `event_id: Mapped[uuid.UUID]` with ForeignKey("events.id", ondelete="CASCADE"), nullable=False, indexed
    - `label: Mapped[str]` with String(200), nullable=False
    - `file_count: Mapped[int]` with Integer, nullable=False, default=0
    - `description: Mapped[str | None]` with Text, nullable=True
    - `file_types: Mapped[str | None]` with String(500), nullable=True (comma-separated like ".pdf, .docx, .xlsx")
    - `sort_order: Mapped[int]` with Integer, nullable=False, default=0
    - `created_at` and `updated_at` with DateTime(timezone=True) and server_default=func.now()
    - Relationship: `event = relationship("Event", back_populates="file_batches", lazy="selectin")`

    Add FileBatch to `server/src/models/__init__.py` exports.

    Also update the Event model (created by Phase 3) to add the back_populates relationship:
    ```python
    file_batches = relationship("FileBatch", back_populates="event",
                                lazy="selectin", order_by="FileBatch.sort_order",
                                cascade="all, delete-orphan")
    ```

    Create Pydantic schemas in `server/src/schemas/file_batch.py`:
    - `FileBatchCreate(BaseModel)`: label (str, max_length=200), file_count (int, ge=0), description (str | None = None), file_types (str | None = None), sort_order (int = 0)
    - `FileBatchUpdate(BaseModel)`: all fields optional (label, file_count, description, file_types, sort_order)
    - `FileBatchRead(BaseModel)`: all fields + id (uuid.UUID), event_id (uuid.UUID), created_at, updated_at. Use `model_config = ConfigDict(from_attributes=True)`

    Create Alembic migration `005_create_file_batches_table.py`:
    - Revision depends on Phase 3's last migration (check actual revision ID)
    - Create `file_batches` table with all columns matching the model
    - Index on event_id for efficient lookups
    - Foreign key to events.id with ON DELETE CASCADE

    Also update the Event read schema (from Phase 3) to include `file_batches: list[FileBatchRead] = []` so batches are returned embedded in event responses.
  </action>
  <verify>
    - `python -c "from src.models.file_batch import FileBatch; print(FileBatch.__tablename__)"` prints "file_batches"
    - `python -c "from src.schemas.file_batch import FileBatchCreate, FileBatchUpdate, FileBatchRead; print('OK')"` prints "OK"
    - Migration file exists and has correct FK reference to events table
  </verify>
  <done>FileBatch model with UUID PK, event FK (CASCADE delete), all metadata fields, Pydantic schemas for create/update/read, and Alembic migration creating the table with proper indexes and foreign key constraints.</done>
</task>

<task type="auto">
  <name>Task 2: File batch CRUD router with event ownership verification</name>
  <files>
    server/src/routers/file_batches.py
    server/src/main.py
  </files>
  <action>
    Create nested CRUD router in `server/src/routers/file_batches.py`:
    - Router prefix: `/cases/{case_id}/events/{event_id}/batches`
    - Tags: `["file-batches"]`

    Helper function `_get_event_or_404(db, event_id, case_id)`:
    - Query Event where Event.id == event_id AND Event.case_id == case_id
    - Raise 404 if not found (ensures event belongs to case -- ownership verification)
    - Return event

    Endpoints (all JWT-protected via `Depends(get_current_user)`):

    1. `POST /` -> Create batch
       - Call `_get_event_or_404` to verify event ownership
       - Create FileBatch with event_id and body fields
       - Return FileBatchRead (201)

    2. `GET /` -> List batches for event
       - Call `_get_event_or_404` to verify event ownership
       - Query file_batches where event_id matches, order by sort_order
       - Return list[FileBatchRead]

    3. `PATCH /{batch_id}` -> Update batch
       - Call `_get_event_or_404` to verify event ownership
       - Query FileBatch by batch_id where event_id matches
       - 404 if not found
       - Apply partial update using model_dump(exclude_unset=True) pattern (same as cases router)
       - Return FileBatchRead

    4. `DELETE /{batch_id}` -> Delete batch
       - Call `_get_event_or_404` to verify event ownership
       - Query FileBatch by batch_id where event_id matches
       - 404 if not found
       - Delete and return 204

    Register router in `server/src/main.py`:
    ```python
    from src.routers.file_batches import router as file_batches_router
    app.include_router(file_batches_router)
    ```
  </action>
  <verify>
    - `python -c "from src.routers.file_batches import router; print(router.prefix)"` confirms prefix
    - `grep -c "include_router.*file_batch" server/src/main.py` returns 1
    - All 4 endpoints (POST, GET, PATCH, DELETE) are defined with correct path parameters
  </verify>
  <done>File batch CRUD router with nested URL structure, event ownership verification (event belongs to case), all four CRUD operations, JWT protection, and proper error handling (404 for missing event/batch). Router registered in main.py.</done>
</task>

</tasks>

<verification>
- FileBatch model exists with correct fields and CASCADE FK to events
- All 4 CRUD endpoints accessible at /cases/{cid}/events/{eid}/batches paths
- Event read schema includes embedded file_batches list
- Router registered in main.py
- Migration file exists with proper dependencies
</verification>

<success_criteria>
- POST creates a batch attached to a specific event and returns it with 201
- GET lists all batches for an event ordered by sort_order
- PATCH partially updates a batch and returns updated data
- DELETE removes a batch and returns 204
- All endpoints verify event belongs to specified case (404 otherwise)
- Deleting an event cascades to delete its batches (via FK CASCADE)
</success_criteria>

<output>
After completion, create `.planning/phases/04-file-batch-grouping/04-01-SUMMARY.md`
</output>
